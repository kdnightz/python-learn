# 2.在GPU上执行程序

1. 自定义的参数和数据 需要转化为cuda支持的tensor
2. model需要转化为cuda支持的model
3. 执行的结果 需要和cpu的tensor计算的时候
   1. tensor.cpu()把cuda的tensor转化为CPU的tensor

# 3. 常见的优化算法介绍

## 3.1 梯度下降算法 （batch gradient descent BGD）

​	每次迭代需要把所有样本都送入，这样的好处是每次迭代都顾忌了全部的样本，做的是**全局最优**化。

​	数据太大，就太慢了

## 3.2 随机梯度下降法（SGD）

​	随机的从样本中抽出一个样本进行梯度的更新

## 3.3 小批量梯度下降（MBGD）

​	找一波数据 计算梯度，使用均值更新参数，效果在1,2中间

## 3.4 动量法

​	基于梯度的移动指数加权平均，对网络的参数进行平滑处理，让梯度的摆动幅度变得更小
$$
&v = 0.8v +0.2 \nabla w &, \nabla w 表示前一次的梯度\\
&w = w- \alpha v &, \alpha 表示学习率
$$
